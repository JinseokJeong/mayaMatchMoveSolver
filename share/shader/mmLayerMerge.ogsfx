// Copyright (C) 2021, 2023 David Cattermole.
//
// This file is part of mmSolver.
//
// mmSolver is free software: you can redistribute it and/or modify it
// under the terms of the GNU Lesser General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// mmSolver is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with mmSolver.  If not, see <https://www.gnu.org/licenses/>.
// --------------------------------------------------------------------
//
// This shader is intended to be similar to "merge" nodes in VFX
// compositing software (e.g. Natron,
// https://natrongithub.github.io/), where the use can merge two input
// streams together.
//
// Layers can also be used as an analogy, such as in Photoshop/GNU
// Image Manipulation Program (GIMP). In the layer methodology, the
// 'A' input is the top layer, and 'B' is the bottom, therefore "A
// over B" means to place source input A over the source input B to
// create an output image.
//
// Unlike real layer merging or VFX compositing, this shader assumes
// the textures given are the same resolution/format. There is no
// handling of different aspect ratios or image position offsets.

// World-view-projection matrix.
uniform mat4 gWVPXf : WorldViewProjection;

// The size of the viewport.
uniform vec2 gTargetSize : ViewportPixelSize;

// Color texture for A input.  Expected to be a normal RGB three
// channel image.
uniform texture2D gColorTexA : InputTexture
<
    string UIName = "Color Texture A";
>;
uniform sampler2D gColorSamplerA = sampler_state {
    Texture = <gColorTexA>;
};

// Depth texture for A input.  Expected to be a single channel zero to
// one image.
uniform texture2D gDepthTexA : InputTexture
<
    string UIName = "Depth Texture A";
>;
uniform sampler2D gDepthSamplerA = sampler_state {
    Texture = <gDepthTexA>;
};

// Color texture for B input.  Expected to be a normal RGB three
// channel image.
uniform texture2D gColorTexB : InputTexture
<
    string UIName = "Color Texture B";
>;
uniform sampler2D gColorSamplerB = sampler_state {
    Texture = <gColorTexB>;
};

// Depth texture for B input.  Expected to be a single channel zero to
// one image.
uniform texture2D gDepthTexB : InputTexture
<
    string UIName = "Depth Texture B";
>;
uniform sampler2D gDepthSamplerB = sampler_state {
    Texture = <gDepthTexB>;
};

// Display for debugging.
#define kDEBUG_MODE_OFF 0
#define kDEBUG_MODE_ON 1
uniform int gDebugMode = 0;

// Merge Mode. How to merge the A and B inputs?
#define kLAYER_MODE_ZDEPTH 0  // Use the Z-Depth channels to merge.
#define kLAYER_MODE_OVER 1    // Classic "A over B".
#define kLAYER_MODE_PLUS 2    // Add A and B together.
uniform int gLayerMode = 0;

// What is the opacity of A input? This can be used to reduce the
// layer merge effect. For example to make input A semi-transparent,
// set the opacity to a value below 1.0.
uniform float gLayerMix = 1.0;

// Vertex Shader inputs.
attribute VS_INPUT {
    vec4 Pos : POSITION;
    vec2 UV : TEXCOORD0;
};

// Vertex Shader outputs.
attribute VS_TO_PS {
    vec2 VSUV : TEXCOORD0;
};

// Vertex Shader
GLSLShader VS_mmLayerMerge {
    void main() {
        gl_Position = gWVPXf * Pos;
        VSUV = UV;
    }
}

// Pixel Shader Outputs
attribute pixelOut {
    vec4 colorOut : COLOR0;
}

GLSLShader PS_mmLayerMerge_Main {
    void main() {
        vec4 result = vec4(0.0, 1.0, 0.0, 1.0);
        vec4 color_A = texture2D(gColorSamplerA, VSUV.xy);
        vec4 color_B = texture2D(gColorSamplerB, VSUV.xy);
        color_A = color_A * gLayerMix;

        if (gLayerMode == kLAYER_MODE_ZDEPTH) {
            vec4 depth_A = texture2D(gDepthSamplerA, VSUV.xy);
            vec4 depth_B = texture2D(gDepthSamplerB, VSUV.xy);

            result = color_B;
            if (depth_A.r <= depth_B.r) {
                result = color_A + (color_B * (1.0 - color_A.a));
            }
        } else if (gLayerMode == kLAYER_MODE_OVER) {
            result = color_A + (color_B * (1.0 - color_A.a));
        } else if (gLayerMode == kLAYER_MODE_PLUS) {
            result = color_A + color_B;
        } else {
            // Linear Blend
            result = vec4(lerp(color_B, color_A, gLayerMix).xyz, color_A.a);

            // Average
            // result = (color_A * 0.5) + (color_B * 0.5);
        }

        if (gDebugMode == kDEBUG_MODE_ON) {
            if (VSUV.x <= 0.125) {
                result = color_A;
            } else if (VSUV.x <= 0.25) {
                if (VSUV.y < 0.5) {
                    result = vec4(color_A.w, color_A.w, color_A.w, 1.0);
                } else {
                    vec4 depth_A = texture2D(gDepthSamplerA, VSUV.xy);
                    result = vec4(depth_A.r, depth_A.r, depth_A.r, 1.0);
                }
            } else if (VSUV.x <= 0.375) {
                result = color_B;
            } else if (VSUV.x <= 0.5) {
                if (VSUV.y < 0.5) {
                    result = vec4(color_B.w, color_B.w, color_B.w, 1.0);
                } else {
                    vec4 depth_B = texture2D(gDepthSamplerB, VSUV.xy);
                    result = vec4(depth_B.r, depth_B.r, depth_B.r, 1.0);
                }
            }
        }

        colorOut = result;
    }
}

// The technique, used to merge textures together.
technique Main {
    pass p0 {
        VertexShader(in VS_INPUT, out VS_TO_PS) = VS_mmLayerMerge;
        PixelShader(in VS_TO_PS, out pixelOut) = PS_mmLayerMerge_Main;
    }
}
